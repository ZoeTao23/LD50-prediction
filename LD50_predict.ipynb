{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a66c4ee-b019-4af3-ad55-a1e75ba221a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0fa963-155a-407d-b2d0-8d6c74907180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTXSID             1912\n",
      "Canonical_QSARr       0\n",
      "LD50_mgkg          2260\n",
      "EPA_category        104\n",
      "GHS_category         34\n",
      "dtype: int64\n",
      "DTXSID             619\n",
      "Canonical_QSARr      0\n",
      "LD50_mgkg          753\n",
      "EPA_category        32\n",
      "GHS_category        11\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6734 entries, 2082 to 8993\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Canonical_QSARr  6734 non-null   object \n",
      " 1   LD50_mgkg        6734 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 157.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8960 entries, 1 to 8993\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Canonical_QSARr  8960 non-null   object \n",
      " 1   GHS_category     8960 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 210.0+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2245 entries, 693 to 2997\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Canonical_QSARr  2245 non-null   object \n",
      " 1   LD50_mgkg        2245 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 52.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2987 entries, 0 to 2997\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Canonical_QSARr  2987 non-null   object \n",
      " 1   GHS_category     2987 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 70.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ------- 1. import data \n",
    "df_train = pd.read_excel('TrainingSet.xlsx', sheet_name=1, header=1)\n",
    "df_train = df_train.loc[:,['DTXSID','Canonical_QSARr','LD50_mgkg','EPA_category','GHS_category']]\n",
    "print(df_train.isna().sum())\n",
    "\n",
    "df_test = pd.read_excel('EvaluationSet.xlsx', sheet_name=1, header=1)\n",
    "df_test = df_test.loc[:,['DTXSID','Canonical_QSARr','LD50_mgkg','EPA_category','GHS_category']]\n",
    "print(df_test.isna().sum())\n",
    "\n",
    "# --(1) train data\n",
    "## response: LD50 \n",
    "train_LD50 = df_train.loc[:,['Canonical_QSARr', 'LD50_mgkg']]\n",
    "train_LD50 = train_LD50.dropna()\n",
    "print(train_LD50.info())\n",
    "\n",
    "## response: CHS_category \n",
    "train_GHS = df_train.loc[:,['Canonical_QSARr', 'GHS_category']]\n",
    "train_GHS = train_GHS.dropna()\n",
    "print(train_GHS.info())\n",
    "\n",
    "# --(2) test data\n",
    "## response: LD50 \n",
    "test_LD50 = df_test.loc[:,['Canonical_QSARr', 'LD50_mgkg']]\n",
    "test_LD50 = test_LD50.dropna()\n",
    "print(test_LD50.info())\n",
    "\n",
    "## response: CHS_category \n",
    "test_GHS = df_test.loc[:,['Canonical_QSARr', 'GHS_category']]\n",
    "test_GHS = test_GHS.dropna()\n",
    "print(test_GHS.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93b4b0f-5451-4488-9cc1-6c2fde4ced65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel(\n",
      "  (conv1): GATConv(10, 128, heads=3)\n",
      "  (conv2): GATConv(384, 128, heads=1)\n",
      "  (lin): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:28:20] Explicit valence for atom # 1 Si, 5, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Train Loss: 19864507.1257 | Test MAE: 2327.3761 | R²: -0.0145\n",
      "Epoch 001 | Train Loss: 17174114.4364 | Test MAE: 2337.4070 | R²: -0.0025\n",
      "Epoch 002 | Train Loss: 17080467.8757 | Test MAE: 2316.0731 | R²: -0.0031\n",
      "Epoch 003 | Train Loss: 17008167.9046 | Test MAE: 2347.4375 | R²: 0.0004\n",
      "Epoch 004 | Train Loss: 17037111.5192 | Test MAE: 2372.4215 | R²: 0.0023\n",
      "Epoch 005 | Train Loss: 16992522.5636 | Test MAE: 2325.8087 | R²: -0.0002\n",
      "Epoch 006 | Train Loss: 16984820.3447 | Test MAE: 2337.5240 | R²: 0.0020\n",
      "Epoch 007 | Train Loss: 16957552.3047 | Test MAE: 2360.9991 | R²: 0.0071\n",
      "Epoch 008 | Train Loss: 17037846.3743 | Test MAE: 2319.4877 | R²: 0.0049\n",
      "Epoch 009 | Train Loss: 16958678.3964 | Test MAE: 2370.3591 | R²: 0.0092\n",
      "Epoch 010 | Train Loss: 16921384.6494 | Test MAE: 2325.5972 | R²: 0.0074\n",
      "Epoch 011 | Train Loss: 16922429.6553 | Test MAE: 2347.9585 | R²: 0.0100\n",
      "Epoch 012 | Train Loss: 16947939.3003 | Test MAE: 2337.4515 | R²: 0.0102\n",
      "Epoch 013 | Train Loss: 16966936.5074 | Test MAE: 2285.3578 | R²: 0.0061\n",
      "Epoch 014 | Train Loss: 16905413.4260 | Test MAE: 2365.5709 | R²: 0.0142\n",
      "Epoch 015 | Train Loss: 16884494.0806 | Test MAE: 2356.6672 | R²: 0.0141\n",
      "Epoch 016 | Train Loss: 16894405.6391 | Test MAE: 2320.8586 | R²: 0.0146\n",
      "Epoch 017 | Train Loss: 16854574.0481 | Test MAE: 2354.8696 | R²: 0.0179\n",
      "Epoch 018 | Train Loss: 16867478.5695 | Test MAE: 2350.9537 | R²: 0.0184\n",
      "Epoch 019 | Train Loss: 16855653.6553 | Test MAE: 2349.8735 | R²: 0.0155\n",
      "Epoch 020 | Train Loss: 16815784.7027 | Test MAE: 2268.0372 | R²: 0.0132\n",
      "Epoch 021 | Train Loss: 16799069.5473 | Test MAE: 2428.2074 | R²: 0.0238\n",
      "Epoch 022 | Train Loss: 16762053.0754 | Test MAE: 2351.1932 | R²: 0.0229\n",
      "Epoch 023 | Train Loss: 16752076.7101 | Test MAE: 2315.1665 | R²: 0.0214\n",
      "Epoch 024 | Train Loss: 16766161.5370 | Test MAE: 2391.6126 | R²: 0.0250\n",
      "Epoch 025 | Train Loss: 16727657.1361 | Test MAE: 2278.4092 | R²: 0.0185\n",
      "Epoch 026 | Train Loss: 16740528.9675 | Test MAE: 2340.7116 | R²: 0.0238\n",
      "Epoch 027 | Train Loss: 16732121.9601 | Test MAE: 2366.9188 | R²: 0.0248\n",
      "Epoch 028 | Train Loss: 16796426.1553 | Test MAE: 2369.4434 | R²: 0.0254\n",
      "Epoch 029 | Train Loss: 16755479.9231 | Test MAE: 2354.4953 | R²: 0.0253\n",
      "Epoch 030 | Train Loss: 16734328.4793 | Test MAE: 2344.4060 | R²: 0.0257\n",
      "Epoch 031 | Train Loss: 16742822.8735 | Test MAE: 2300.3766 | R²: 0.0226\n",
      "Epoch 032 | Train Loss: 16727449.4497 | Test MAE: 2372.8498 | R²: 0.0269\n",
      "Epoch 033 | Train Loss: 16740791.0133 | Test MAE: 2314.2262 | R²: 0.0239\n",
      "Epoch 034 | Train Loss: 16771521.8402 | Test MAE: 2344.3746 | R²: 0.0263\n",
      "Epoch 035 | Train Loss: 17167047.2692 | Test MAE: 2369.8931 | R²: 0.0262\n",
      "Epoch 036 | Train Loss: 16754361.2004 | Test MAE: 2407.4764 | R²: 0.0258\n",
      "Epoch 037 | Train Loss: 16717990.2870 | Test MAE: 2390.7395 | R²: 0.0280\n",
      "Epoch 038 | Train Loss: 16773721.8077 | Test MAE: 2367.4242 | R²: 0.0255\n",
      "Epoch 039 | Train Loss: 16742106.5680 | Test MAE: 2348.8781 | R²: 0.0269\n",
      "Epoch 040 | Train Loss: 16760883.8831 | Test MAE: 2410.0288 | R²: 0.0286\n",
      "Epoch 041 | Train Loss: 16712216.7988 | Test MAE: 2385.2276 | R²: 0.0281\n",
      "Epoch 042 | Train Loss: 16698975.2086 | Test MAE: 2327.3966 | R²: 0.0264\n",
      "Epoch 043 | Train Loss: 16705594.0799 | Test MAE: 2363.2044 | R²: 0.0273\n",
      "Epoch 044 | Train Loss: 16699395.8462 | Test MAE: 2311.7858 | R²: 0.0249\n",
      "Epoch 045 | Train Loss: 16723605.9867 | Test MAE: 2349.3221 | R²: 0.0280\n",
      "Epoch 046 | Train Loss: 16729528.0769 | Test MAE: 2413.1221 | R²: 0.0296\n",
      "Epoch 047 | Train Loss: 16686145.4667 | Test MAE: 2297.7257 | R²: 0.0255\n",
      "Epoch 048 | Train Loss: 16721294.2130 | Test MAE: 2352.2690 | R²: 0.0291\n",
      "Epoch 049 | Train Loss: 16727999.5370 | Test MAE: 2374.0234 | R²: 0.0299\n",
      "Epoch 050 | Train Loss: 16670400.4083 | Test MAE: 2271.9886 | R²: 0.0239\n",
      "Epoch 051 | Train Loss: 16683686.5340 | Test MAE: 2322.8212 | R²: 0.0286\n",
      "Epoch 052 | Train Loss: 16656069.9571 | Test MAE: 2358.0600 | R²: 0.0307\n",
      "Epoch 053 | Train Loss: 16665688.7840 | Test MAE: 2378.4088 | R²: 0.0311\n",
      "Epoch 054 | Train Loss: 16673372.7337 | Test MAE: 2370.1577 | R²: 0.0313\n",
      "Epoch 055 | Train Loss: 16700643.9393 | Test MAE: 2343.4240 | R²: 0.0306\n",
      "Epoch 056 | Train Loss: 16699993.6849 | Test MAE: 2341.3125 | R²: 0.0308\n",
      "Epoch 057 | Train Loss: 16645811.0266 | Test MAE: 2415.0673 | R²: 0.0299\n",
      "Epoch 058 | Train Loss: 16622923.4290 | Test MAE: 2285.8887 | R²: 0.0290\n",
      "Epoch 059 | Train Loss: 18552871.7086 | Test MAE: 2390.8202 | R²: 0.0325\n",
      "Epoch 060 | Train Loss: 16617479.1723 | Test MAE: 2301.1904 | R²: 0.0275\n",
      "Epoch 061 | Train Loss: 16630989.2041 | Test MAE: 2419.8893 | R²: 0.0313\n",
      "Epoch 062 | Train Loss: 16698741.4157 | Test MAE: 2433.3600 | R²: 0.0325\n",
      "Epoch 063 | Train Loss: 16625373.5192 | Test MAE: 2352.5011 | R²: 0.0320\n",
      "Epoch 064 | Train Loss: 16664881.1109 | Test MAE: 2379.6485 | R²: 0.0340\n",
      "Epoch 065 | Train Loss: 17028103.9970 | Test MAE: 2378.5270 | R²: 0.0343\n",
      "Epoch 066 | Train Loss: 16653988.0547 | Test MAE: 2298.3937 | R²: 0.0319\n",
      "Epoch 067 | Train Loss: 16596189.3979 | Test MAE: 2377.6899 | R²: 0.0338\n",
      "Epoch 068 | Train Loss: 16726207.4749 | Test MAE: 2299.2248 | R²: 0.0325\n",
      "Epoch 069 | Train Loss: 16593232.4719 | Test MAE: 2358.4705 | R²: 0.0354\n",
      "Epoch 070 | Train Loss: 16577785.9852 | Test MAE: 2302.9766 | R²: 0.0333\n",
      "Epoch 071 | Train Loss: 16541269.8987 | Test MAE: 2273.0437 | R²: 0.0314\n",
      "Epoch 072 | Train Loss: 16692800.1524 | Test MAE: 2284.0974 | R²: 0.0340\n",
      "Epoch 073 | Train Loss: 16574544.7145 | Test MAE: 2295.8774 | R²: 0.0329\n",
      "Epoch 074 | Train Loss: 16544923.5385 | Test MAE: 2346.9713 | R²: 0.0357\n",
      "Epoch 075 | Train Loss: 16567329.7308 | Test MAE: 2309.7255 | R²: 0.0348\n",
      "Epoch 076 | Train Loss: 16612014.3757 | Test MAE: 2339.8959 | R²: 0.0372\n",
      "Epoch 077 | Train Loss: 16638838.5059 | Test MAE: 2270.0869 | R²: 0.0313\n",
      "Epoch 078 | Train Loss: 16850920.4194 | Test MAE: 2383.9284 | R²: 0.0364\n",
      "Epoch 079 | Train Loss: 16553552.4497 | Test MAE: 2354.8222 | R²: 0.0372\n",
      "Epoch 080 | Train Loss: 16542136.6109 | Test MAE: 2355.1947 | R²: 0.0371\n",
      "Epoch 081 | Train Loss: 16575387.7544 | Test MAE: 2415.9272 | R²: 0.0372\n",
      "Epoch 082 | Train Loss: 16499820.7441 | Test MAE: 2439.6181 | R²: 0.0371\n",
      "Epoch 083 | Train Loss: 16543815.2041 | Test MAE: 2352.2187 | R²: 0.0378\n",
      "Epoch 084 | Train Loss: 16530611.1472 | Test MAE: 2321.2850 | R²: 0.0382\n",
      "Epoch 085 | Train Loss: 16545316.5163 | Test MAE: 2439.1111 | R²: 0.0398\n",
      "Epoch 086 | Train Loss: 16521164.8994 | Test MAE: 2311.1579 | R²: 0.0341\n",
      "Epoch 087 | Train Loss: 16565143.3905 | Test MAE: 2367.8774 | R²: 0.0374\n",
      "Epoch 088 | Train Loss: 16539039.1967 | Test MAE: 2318.8621 | R²: 0.0363\n",
      "Epoch 089 | Train Loss: 16534414.7197 | Test MAE: 2351.2935 | R²: 0.0381\n",
      "Epoch 090 | Train Loss: 16570492.7249 | Test MAE: 2367.1793 | R²: 0.0390\n",
      "Epoch 091 | Train Loss: 16573703.5518 | Test MAE: 2357.1428 | R²: 0.0379\n",
      "Epoch 092 | Train Loss: 16530025.8861 | Test MAE: 2285.3335 | R²: 0.0373\n",
      "Epoch 093 | Train Loss: 16518965.3432 | Test MAE: 2317.0711 | R²: 0.0400\n",
      "Epoch 094 | Train Loss: 16478413.9482 | Test MAE: 2349.1456 | R²: 0.0388\n",
      "Epoch 095 | Train Loss: 16573319.4497 | Test MAE: 2301.3505 | R²: 0.0408\n",
      "Epoch 096 | Train Loss: 16486435.9578 | Test MAE: 2354.1139 | R²: 0.0416\n",
      "Epoch 097 | Train Loss: 16479030.5858 | Test MAE: 2342.6184 | R²: 0.0421\n",
      "Epoch 098 | Train Loss: 16499303.2027 | Test MAE: 2297.3849 | R²: 0.0402\n",
      "Epoch 099 | Train Loss: 16700030.5518 | Test MAE: 2418.5774 | R²: 0.0425\n"
     ]
    }
   ],
   "source": [
    "# ------- 2. model  \n",
    "\n",
    "# -- (1) GNN\n",
    "\n",
    "## data preprocess\n",
    "def smiles_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if not mol:\n",
    "        return None\n",
    "    \n",
    "    # 原子特征（10维）\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        feature = [\n",
    "            atom.GetAtomicNum(),          # 原子序数\n",
    "            atom.GetDegree(),             # 连接度\n",
    "            atom.GetImplicitValence(),    # 隐式价\n",
    "            int(atom.GetIsAromatic()),    # 芳香性\n",
    "            atom.GetFormalCharge(),       # 形式电荷\n",
    "            atom.GetNumRadicalElectrons(), # 自由基电子\n",
    "            atom.GetHybridization().real, # 杂化类型\n",
    "            atom.GetTotalNumHs(),         # 连接氢数\n",
    "            int(atom.IsInRing()),         # 是否在环中\n",
    "            atom.GetChiralTag().real      # 手性\n",
    "        ]\n",
    "        atom_features.append(feature)\n",
    "    \n",
    "    # 边索引（化学键）\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.extend([[i, j], [j, i]])  # 无向图\n",
    "    \n",
    "    # 边特征（3维）\n",
    "    edge_attr = []\n",
    "    for bond in mol.GetBonds():\n",
    "        bond_features = [\n",
    "            bond.GetBondTypeAsDouble(),   # 键类型\n",
    "            int(bond.IsInRing()),         # 是否在环中\n",
    "            int(bond.GetIsConjugated())   # 是否共轭\n",
    "        ]\n",
    "        edge_attr.extend([bond_features, bond_features])\n",
    "    \n",
    "    return Data(\n",
    "        x=torch.tensor(atom_features, dtype=torch.float),\n",
    "        edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous(),\n",
    "        edge_attr=torch.tensor(edge_attr, dtype=torch.float)\n",
    "    )\n",
    "\n",
    "# test \n",
    "# smiles = \"CCO\"  \n",
    "# graph = smiles_to_graph(smiles)\n",
    "# print(graph)   \n",
    "    \n",
    "## model\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, num_node_features=10, hidden_dim=128, output_dim=1):\n",
    "        super().__init__()\n",
    "        # 图注意力层\n",
    "        self.conv1 = GATConv(num_node_features, hidden_dim, heads=3)\n",
    "        self.conv2 = GATConv(hidden_dim*3, hidden_dim)  # 注意heads=3的输出维度是hidden_dim*3\n",
    "        self.lin = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # 1. 图卷积\n",
    "        x = F.leaky_relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.leaky_relu(self.conv2(x, edge_index))\n",
    "        \n",
    "        # 2. 全局池化\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # 3. 回归输出\n",
    "        return self.lin(x).squeeze(-1)\n",
    "\n",
    "\n",
    "# 初始化模型\n",
    "model = GNNModel(num_node_features=10, hidden_dim=128)\n",
    "print(model)\n",
    "\n",
    "graphs = []\n",
    "labels = []\n",
    "for smiles, ld50 in zip(train_LD50['Canonical_QSARr'], train_LD50['LD50_mgkg']):\n",
    "    g = smiles_to_graph(smiles)\n",
    "    if g is not None:\n",
    "        graphs.append(g)\n",
    "        labels.append(ld50)\n",
    "labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "\n",
    "# 划分训练集/测试集\n",
    "train_graphs, test_graphs, train_labels, test_labels = train_test_split(\n",
    "    graphs, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 创建DataLoader\n",
    "train_loader = DataLoader(\n",
    "    list(zip(train_graphs, train_labels)),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_graphs, test_labels)),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# 训练配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "# criterion = nn.HuberLoss()  # 对异常值鲁棒的损失函数\n",
    "criterion = nn.MSELoss()  # 回归任务用均方误差\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "best_mae = float('inf')\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    # 训练\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data in train_loader:\n",
    "        graph, label = data\n",
    "        graph, label = graph.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(graph)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # 测试\n",
    "    model.eval()\n",
    "    preds, truths = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            graph, label = data\n",
    "            graph = graph.to(device)\n",
    "            preds.extend(model(graph).cpu().tolist())\n",
    "            truths.extend(label.tolist())\n",
    "    \n",
    "    # 计算指标\n",
    "    mae = mean_absolute_error(truths, preds)\n",
    "    r2 = r2_score(truths, preds)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'metrics': {'mae': mae, 'r2': r2}\n",
    "        }, \"results/best_model.pth\")\n",
    "    \n",
    "    # 打印进度\n",
    "    print(f\"Epoch {epoch:03d} | \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Test MAE: {mae:.4f} | \"\n",
    "          f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f943a92-f43b-4c34-9e84-4bd76dd06164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) transformer\n",
    "\n",
    "\n",
    "# 加载预训练化学 Transformer（如 ChemBERTa）\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"DeepChem/ChemBERTa-77M-MLM\", \n",
    "    num_labels=1  # 回归任务\n",
    ")\n",
    "\n",
    "# 输入处理\n",
    "smiles = \"CCO\"  # 示例\n",
    "inputs = tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "ld50_pred = outputs.logits.squeeze()  # 预测值\n",
    "\n",
    "# (3) mixed model（GNN + describor）\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, gnn_hidden_dim=64, desc_dim=200):\n",
    "        super().__init__()\n",
    "        # GNN 分支\n",
    "        self.gnn = GNNModel(hidden_dim=gnn_hidden_dim)\n",
    "        # 描述符分支\n",
    "        self.desc_fc = nn.Sequential(\n",
    "            nn.Linear(desc_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        # 联合回归头\n",
    "        self.fc = nn.Linear(gnn_hidden_dim + 32, 1)\n",
    "\n",
    "    def forward(self, graph_data, descriptors):\n",
    "        gnn_out = self.gnn(graph_data)            # GNN 特征\n",
    "        desc_out = self.desc_fc(descriptors)      # 描述符特征\n",
    "        combined = torch.cat([gnn_out, desc_out], dim=1)\n",
    "        return self.fc(combined).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7af5a-d633-4596-8ca5-88fe4bc52688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aaa2c4-b706-413c-bf66-0c16f47d7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- 3. train  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f96980-d663-45f2-81fa-f68c1ff26db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical_QSARr</th>\n",
       "      <th>GHS_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(NC1C=C(Cl)C(Cl)=CC=1)NC1C=CC(Cl)=CC=1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCCCCCC(O)=O</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC12CC(C)CC(CCCCCCCC(O)CC3OC(O)(CC(O)C(C)C=CC(...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1(C)OC2CC3C4CC(F)C5=CC(=O)C=CC5(C)C4C(O)CC3(...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[H]N=C(N)NCCCCC1NC(=O)C(C)C(NC(=O)C(CC(C)C)NC(...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>OC(=O)CN(CC(O)=O)CC(O)=O</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8990</th>\n",
       "      <td>CCO</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>OCCOC1C=CC=CC=1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>OCCO</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8993</th>\n",
       "      <td>CC(=O)OO</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Canonical_QSARr  GHS_category\n",
       "1             O=C(NC1C=C(Cl)C(Cl)=CC=1)NC1C=CC(Cl)=CC=1           5.0\n",
       "2                                        CCCCCCCCC(O)=O           5.0\n",
       "3     CC12CC(C)CC(CCCCCCCC(O)CC3OC(O)(CC(O)C(C)C=CC(...           1.0\n",
       "4     CC1(C)OC2CC3C4CC(F)C5=CC(=O)C=CC5(C)C4C(O)CC3(...           1.0\n",
       "5     [H]N=C(N)NCCCCC1NC(=O)C(C)C(NC(=O)C(CC(C)C)NC(...           2.0\n",
       "...                                                 ...           ...\n",
       "8989                           OC(=O)CN(CC(O)=O)CC(O)=O           4.0\n",
       "8990                                                CCO           5.0\n",
       "8991                                    OCCOC1C=CC=CC=1           4.0\n",
       "8992                                               OCCO           5.0\n",
       "8993                                           CC(=O)OO           2.0\n",
       "\n",
       "[8960 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------- 4. test \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae86559-4c29-4834-ab75-dda7c3d5607a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02288b32-2842-45db-8ab5-f393cb84077f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
